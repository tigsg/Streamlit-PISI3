{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908b9889-ba36-4004-a67e-36947eaeb8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando os clusters\n",
    "#Importando bibliotecas\n",
    "%pip install kmodes\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install plotly\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from kmodes.kmodes import KModes\n",
    "from kmodes.util.dissim import jaccard_dissim_binary\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "667b5609-2346-4b0a-8d07-e97dc03e04f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregando os dados\n",
    "dataset = pd.read_parquet(\"TMDB_movie_dataset_v11(com correçao)_updated.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7363b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pareto paises\n",
    "def diagrama_pareto(data_frame, coluna, titulo):\n",
    "\n",
    "    #Contando as aparições de dados\n",
    "    dados_separados = data_frame[coluna].str.split(', ').explode()\n",
    "    aparicoes_dados = dados_separados.value_counts().sort_values(ascending=False)\n",
    "    agrupado = aparicoes_dados.reset_index(name='Contagem')\n",
    "    agrupado = agrupado.sort_values('Contagem', ascending=False)\n",
    "\n",
    "    #Criando a série do somas acumulativas\n",
    "    agrupado['Acumulado'] = agrupado['Contagem'].cumsum() / agrupado['Contagem'].sum() * 100\n",
    "\n",
    "    #Criando a barra 'outros' após a linha atingir os 70%\n",
    "    agrupado_principal = agrupado[agrupado['Acumulado'] <= 70]\n",
    "    agrupado_outros = agrupado[agrupado['Acumulado'] > 70]\n",
    "    outros_contagem = agrupado_outros['Contagem'].sum()\n",
    "    linha_outros = pd.DataFrame({coluna: ['Outros'], 'Contagem': [outros_contagem], 'Acumulado': [100]})\n",
    "    agrupado_principal = pd.concat([agrupado_principal, linha_outros], ignore_index=True)\n",
    "    return agrupado_principal\n",
    "\n",
    "\n",
    "paises_principais= diagrama_pareto(dataset, 'production_countries', 'Produção por País')\n",
    "\n",
    "print(paises_principais)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeee8d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pareto linguas\n",
    "def diagrama_pareto_linguas(data_frame, coluna, titulo):\n",
    "\n",
    "    # Contando as aparições de dados\n",
    "    dados_separados = data_frame[coluna].str.split(', ').explode()\n",
    "    aparicoes_dados = dados_separados.value_counts().sort_values(ascending=False)\n",
    "    agrupado = aparicoes_dados.reset_index(name='Contagem')\n",
    "    agrupado = agrupado.sort_values('Contagem', ascending=False)\n",
    "\n",
    "    # Criando a série do somas acumulativas\n",
    "    agrupado['Acumulado'] = agrupado['Contagem'].cumsum() / agrupado['Contagem'].sum() * 100\n",
    "\n",
    "    # Criando a barra 'outros' após a linha atingir os 70%\n",
    "    agrupado_principal = agrupado[agrupado['Acumulado'] <= 70]\n",
    "    agrupado_outros = agrupado[agrupado['Acumulado'] > 70]\n",
    "    outros_contagem = agrupado_outros['Contagem'].sum()\n",
    "    linha_outros = pd.DataFrame({coluna: ['Outros'], 'Contagem': [outros_contagem], 'Acumulado': [100]})\n",
    "    agrupado_principal = pd.concat([agrupado_principal, linha_outros], ignore_index=True)\n",
    "    return agrupado_principal\n",
    "\n",
    "linguas_principais = diagrama_pareto_linguas(dataset, 'spoken_languages', 'Línguas Faladas')\n",
    "\n",
    "print(linguas_principais)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259f64d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#onehotencoding paises\n",
    "def onehotencoding(df, coluna):\n",
    "    a_clusterizar = ['id', 'title', coluna]\n",
    "    dataset_cluster = df[a_clusterizar].copy()\n",
    "    \n",
    "    # Fill None values with an empty string\n",
    "    dataset_cluster[coluna] = dataset_cluster[coluna].fillna('')\n",
    "    \n",
    "    # Obtendo os valores únicos da coluna\n",
    "    valores = paises_principais['production_countries'].values\n",
    "    \n",
    "    # Criando um DataFrame com todas as colunas de uma vez para evitar erro de defragmentação\n",
    "    one_hot_data = {\n",
    "        valor: dataset_cluster[coluna].apply(lambda x: 1 if valor in x else 0)\n",
    "        for valor in valores\n",
    "    }\n",
    "    dataset_coluna = pd.DataFrame(one_hot_data, index=dataset_cluster.index)\n",
    "    \n",
    "    return dataset_coluna\n",
    "\n",
    "onehotpaises = onehotencoding(dataset, 'production_countries')\n",
    "\n",
    "print(onehotpaises.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb4a30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Teste para checar se a tabela binária que passará pela clusterização foi feita corretamente\n",
    "onehotpaises.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f0f63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# onehotencoding linguas\n",
    "def onehotencoding_linguas(df, coluna):\n",
    "    a_clusterizar = ['id', 'title', coluna]\n",
    "    dataset_cluster = df[a_clusterizar].copy()\n",
    "    \n",
    "    # Fill None values with an empty string\n",
    "    dataset_cluster[coluna] = dataset_cluster[coluna].fillna('')\n",
    "    \n",
    "    # Obtendo os valores únicos da coluna\n",
    "    valores = linguas_principais['spoken_languages'].values\n",
    "    \n",
    "    # Criando um DataFrame com todas as colunas de uma vez para evitar erro de defragmentação\n",
    "    one_hot_data = {\n",
    "        valor: dataset_cluster[coluna].apply(lambda x: 1 if valor in x else 0)\n",
    "        for valor in valores\n",
    "    }\n",
    "    dataset_coluna = pd.DataFrame(one_hot_data, index=dataset_cluster.index)\n",
    "    \n",
    "    return dataset_coluna\n",
    "\n",
    "onehotlinguas = onehotencoding_linguas(dataset, 'spoken_languages')\n",
    "\n",
    "print(onehotlinguas.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4eabad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Teste para checar se a tabela binária que passará pela clusterização foi feita corretamente\n",
    "onehotlinguas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bd63bed-1cd5-444b-8552-a26dea95166d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#onehotencoding\n",
    "def onehotencoding(df, coluna):\n",
    "    a_clusterizar = ['id', 'title', coluna]\n",
    "    dataset_cluster = df[a_clusterizar].copy()\n",
    "    \n",
    "    # Obtendo os valores únicos da coluna\n",
    "    valores = dataset_cluster[coluna].str.split(', ').explode().unique()\n",
    "    \n",
    "    # Criando um DataFrame com todas as colunas de uma vez para evitar erro de defragmentação\n",
    "    one_hot_data = {\n",
    "        valor: dataset_cluster[coluna].apply(lambda x: 1 if valor in x else 0)\n",
    "        for valor in valores\n",
    "    }\n",
    "    dataset_coluna = pd.DataFrame(one_hot_data, index=dataset_cluster.index)\n",
    "    \n",
    "    return dataset_coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a95459d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clusterização\n",
    "#Criando a tabela utilizando one-hot encoding\n",
    "#Criando a tabela binária com os gêneros\n",
    "\n",
    "# Fill None values with an empty string\n",
    "dataset['genres'] = dataset['genres'].fillna('')\n",
    "\n",
    "bin_generos = onehotencoding(dataset, 'genres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a291d03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Teste para checar se a tabela binária que passará pela clusterização foi feita corretamente\n",
    "bin_generos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cfe6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Juntando os atributos spoken_languages, production_countries e genres\n",
    "combined_attributes = pd.concat([onehotlinguas, onehotpaises, bin_generos], axis=1)\n",
    "\n",
    "# Exibindo as primeiras linhas do dataframe combinado\n",
    "print(combined_attributes.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0731d93-cd23-4112-8e0c-9b75e1109a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#elbowmethod\n",
    "def elbowmethod(tabela_binaria):\n",
    "    #Lista para preencher com a série de wcss\n",
    "    wcss = []\n",
    "\n",
    "    #Preenchendo a lista\n",
    "    for k in range(1, 11):\n",
    "        km = KModes(n_clusters=k, init='random', n_init=10, verbose=1, max_iter = 100, cat_dissim = jaccard_dissim_binary, random_state = 42)\n",
    "        km.fit(tabela_binaria)\n",
    "        wcss.append(km.cost_)\n",
    "        \n",
    "    #Criando o gráfico com a Plotly para demonstrar o resultado do Elbow Method\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=list(range(1, 11)),\n",
    "        y=wcss,\n",
    "        mode='lines+markers',\n",
    "        name='WCSS',\n",
    "        line=dict(color='royalblue', dash='dash'),\n",
    "        marker=dict(size=8)\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Elbow Method',\n",
    "        xaxis_title='Número de Clusters (k)',\n",
    "        yaxis_title='WCSS',\n",
    "        xaxis=dict(tickmode='linear', tick0=1, dtick=1),\n",
    "        template='plotly_white'\n",
    "    )\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23df97e2-f1c6-45e6-b1ef-bb2ee16f4f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicando o elbowmethod\n",
    "serie_wcss = elbowmethod(bin_generos)\n",
    "serie_wcss.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1acde6",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "#Criando os clusters com o valor ideal de k\n",
    "clusters_generos = KModes(n_clusters=6, init='random', n_init=10, verbose=2, max_iter = 100, cat_dissim = jaccard_dissim_binary, random_state = 42)\n",
    "clusters_generos.fit(bin_generos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "687a7dcf-15ef-4a5c-a990-a1db9840dc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adicionando a coluna 'cluster'\n",
    "dataset['cluster'] = clusters_generos.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abae129-58b1-4ee2-b90d-4513c3c6981d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exibindo o dataframe agora com uma coluna 'cluster' apresentando o cluster em que cada registro ficou\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7db10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista dos países principais\n",
    "selected_countries = ['United States of America', 'France', 'Germany', 'Japan', 'United Kingdom', 'Canada', 'India', 'Italy', 'Brazil', 'Spain', 'Mexico', 'China']\n",
    "\n",
    "# Função para criar as colunas dos países principais e a coluna 'Outros'\n",
    "def create_country_columns(df, countries):\n",
    "    # Fill None values with an empty string\n",
    "    df['production_countries'] = df['production_countries'].fillna('')\n",
    "    for country in countries:\n",
    "        df[country] = df['production_countries'].apply(lambda x: 1 if country in x else 0)\n",
    "    df['Outros'] = df['production_countries'].apply(lambda x: 1 if not any(country in x for country in countries) else 0)\n",
    "    return df\n",
    "\n",
    "# Aplicando a função ao dataset\n",
    "dataset = create_country_columns(dataset, selected_countries)\n",
    "\n",
    "# Exibindo as primeiras linhas do dataframe atualizado\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2375ae8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kmodes.kmodes import KModes\n",
    "from kmodes.util.dissim import jaccard_dissim_binary\n",
    "\n",
    "# Instalar o kmodes\n",
    "%pip install kmodes\n",
    "\n",
    "# Criar a tabela binária para os principais países\n",
    "bin_paises = onehotpaises\n",
    "\n",
    "# Remover linhas com todos os valores zero\n",
    "bin_paises = bin_paises[(bin_paises.T != 0).any()]\n",
    "\n",
    "# Realizar a clusterização usando o KModes\n",
    "clusters_paises = KModes(n_clusters=6, init='random', n_init=10, verbose=2, max_iter=100, cat_dissim=jaccard_dissim_binary, random_state=42)\n",
    "clusters_paises.fit(bin_paises)\n",
    "\n",
    "# Adicionar a coluna 'cluster' ao dataset\n",
    "dataset['cluster_paises'] = clusters_paises.labels_\n",
    "\n",
    "# Exibir as primeiras linhas do dataframe atualizado\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518afd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kmodes.kmodes import KModes\n",
    "from kmodes.util.dissim import jaccard_dissim_binary\n",
    "\n",
    "# Criar a tabela binária para os gêneros\n",
    "bin_generos = onehotencoding(dataset, 'genres')\n",
    "\n",
    "# Remover linhas com todos os valores zero\n",
    "bin_generos = bin_generos[(bin_generos.T != 0).any()]\n",
    "\n",
    "# Realizar a clusterização usando o KModes\n",
    "clusters_generos = KModes(n_clusters=6, init='random', n_init=10, verbose=2, max_iter=100, cat_dissim=jaccard_dissim_binary, random_state=42)\n",
    "clusters_generos.fit(bin_generos)\n",
    "\n",
    "# Adicionar a coluna 'cluster_generos' ao dataset\n",
    "dataset['cluster_generos'] = clusters_generos.labels_\n",
    "\n",
    "# Exibir as primeiras linhas do dataframe atualizado\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccb78f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Adicionando a coluna 'cluster_paises' ao dataset\n",
    "dataset['cluster_paises'] = clusters_paises.labels_\n",
    "\n",
    "# Plotando o gráfico de dispersão\n",
    "fig = px.scatter(\n",
    "    dataset,\n",
    "    x='id',\n",
    "    y='cluster_paises',\n",
    "    color='cluster_paises',\n",
    "    title='Gráfico de Dispersão dos Clusters de Países',\n",
    "    labels={'id': 'ID do Filme', 'cluster_paises': 'Cluster'}\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19196b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Adicionando a coluna 'cluster_generos' ao dataset\n",
    "dataset['cluster_generos'] = clusters_generos.labels_\n",
    "\n",
    "# Plotando o gráfico de dispersão\n",
    "fig = px.scatter(\n",
    "    dataset,\n",
    "    x='id',\n",
    "    y='cluster_generos',\n",
    "    color='cluster_generos',\n",
    "    title='Gráfico de Dispersão dos Clusters de Gêneros',\n",
    "    labels={'id': 'ID do Filme', 'cluster_generos': 'Cluster'}\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
